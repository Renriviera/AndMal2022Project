{
  "hash": "1d5c4ab63465c7647846cbf1058e4d6c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"EDAV Proposal\"\nformat: html\n---\n\n### Project Proposal:\n\nEDAV project on android malware/benign code\n\nI am interested in this area because I think cybersecurity does not get enough mainstream recognition- it is critical to the well-being of every other sector, it is also a data-rich(data quality is high too) computer centric field. Recently global events like the crowdstrike fiasco piqued my interest. I have always wanted to try doing some work in cybersecurity and this will be the first time! \n### Questions:\nHow imbalanced are the various categories and families of malware. What sort of permissions and API calls are most distinctive for each? What about memory/battery usage or network profiles?  Zero-days are never-seen before malware that exploit vulnerabilities previously unknown. There is also code that could not compile in the lab environment with reasons listed why. Should these be just considered as outliers or is there valuable knowledge to be gained from contrastive EDAV? \n\n### Datasets I plan to use(I will use the first link listed but listed other relevant ones as well):\nhttps://www.unb.ca/cic/datasets/maldroid-2020.html\nCollected by UNB's Canadian Institute for Cybersecurity from various(cited in the link) reputable sources.\n— have access already, 17341 samples until 2018, 5 categories: Adware, Banking malware, SMS malware, Riskware, and Benign, APK files: 17,341 Android samples spanning between five distinct categories: Adware, Banking malware, SMS malware, Riskware, and Benign.\nCapturing-logs: The output analysis results of 13,077 samples in five categories: Adware, Banking malware, SMS malware, Riskware, and Benign.\nCSV files:\n470 extracted features for 11,598 APK files comprising frequencies of system calls, binders, and composite behaviors\n139 extracted features for 11,598 APK files comprising frequencies of system calls\n50,621 extracted features for 11,598 APK files comprising static information, such as intent actions, permissions, intent consts, permissions, files, method tags, sensitive APIs, services, packages, receivers, etc.\n\n### Other interesting sources:\n\nhttps://www.unb.ca/cic/datasets/andmal2020.html \n— have access already,  big dataset 400k samples\nhttps://androzoo.uni.lu/?utm_source=chatgpt.com\n— don’t have access yes, very big dataset 20M+ samples\nhttps://data.mendeley.com/datasets/rvjptkrc34/1\n— have access already, small 1500 samples\n\n### Load Libraries and Preprocessed Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.2.0     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(viridis)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: viridisLite\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(scales)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:viridis':\n\n    viridis_pal\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(tidyr)\nlibrary(ggdensity)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load preprocessed data from preprocessing.qmd\nandmal_after <- readRDS(\"data/processed/andmal_after.rds\")\nandmal_before <- readRDS(\"data/processed/andmal_before.rds\")\nfeature_definitions <- readRDS(\"data/processed/feature_definitions.rds\")\n\n# Extract feature definitions for use in visualizations\nui_features <- feature_definitions$ui_features\ndex_apis <- feature_definitions$dex_apis\nwebview_cols <- feature_definitions$webview_cols\nfileio_apis <- feature_definitions$fileio_apis\ndb_apis <- feature_definitions$db_apis\ndb_read_apis <- feature_definitions$db_read_apis\ndb_write_apis <- feature_definitions$db_write_apis\nfiledb_apis <- feature_definitions$filedb_apis\n\n# Global color scheme\nandmal_theme <- theme_minimal(base_family = \"sans\") +\n  theme(\n    plot.title    = element_text(face = \"bold\", hjust = 0),\n    plot.subtitle = element_text(hjust = 0),\n    axis.text.x   = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\"\n  )\n\ncategory_col  <- scale_colour_viridis_d(option = \"H\", end = 0.9)\ncategory_fill <- scale_fill_viridis_d(option = \"H\", end = 0.9)\n\ncat(sprintf(\"Loaded andmal_after: %d rows, %d columns\\n\", nrow(andmal_after), ncol(andmal_after)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLoaded andmal_after: 25059 rows, 185 columns\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(sprintf(\"Loaded andmal_before: %d rows, %d columns\\n\", nrow(andmal_before), ncol(andmal_before)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLoaded andmal_before: 28380 rows, 188 columns\n```\n\n\n:::\n:::\n\n\n## Visualizations\n\n\n::: {.cell}\n\n:::\n\n\n### Memory Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensure required libraries are loaded (defensive in case cached session missed load step)\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(scales)\nlibrary(viridis)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: viridisLite\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'viridis'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:scales':\n\n    viridis_pal\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidyr)\nlibrary(tibble)\n\n\n\n# 1) Category-level means for all File/DB APIs ----\nfiledb_means <- get_combined_data() %>%\n  select(Category, all_of(filedb_apis)) %>%\n  group_by(Category) %>%\n  summarise(\n    across(everything(), ~ mean(.x, na.rm = TRUE)),\n    .groups = \"drop\"\n  )\n\n# Turn into matrix: rows = Categories, cols = APIs ----\nfiledb_mat <- filedb_means %>%\n  column_to_rownames(\"Category\") %>%\n  as.matrix()\n\n# Replace NaN/Inf (e.g., mean of all-NA column) with 0 ----\nfiledb_mat[!is.finite(filedb_mat)] <- 0\n\n# 2) Drop APIs with zero variance (no information) ----\ncol_sds <- apply(filedb_mat, 2, sd, na.rm = TRUE)\n\nkeep_cols <- names(col_sds)[col_sds > 0 & !is.na(col_sds)]\nfiledb_mat2 <- filedb_mat[, keep_cols, drop = FALSE]\n\n# 3) Z-score across categories per API ----\nfiledb_mat_scaled <- scale(filedb_mat2)  # center & scale each column\n\n# 4) Hierarchical clustering on rows (Categories) and columns (APIs) ----\nrow_clust <- hclust(dist(filedb_mat_scaled))\ncol_clust <- hclust(dist(t(filedb_mat_scaled)))\n\nrow_order <- rownames(filedb_mat_scaled)[row_clust$order]\ncol_order <- colnames(filedb_mat_scaled)[col_clust$order]\n\n# 5) Long format for ggplot, using clustered ordering ----\nfiledb_long <- as.data.frame(filedb_mat_scaled) %>%\n  rownames_to_column(\"Category\") %>%\n  pivot_longer(\n    cols      = -Category,\n    names_to  = \"api_call\",\n    values_to = \"z_mean_calls\"\n  ) %>%\n  mutate(\n    Category = factor(Category, levels = row_order),\n    api_call = factor(api_call, levels = col_order)\n  )\n\n# 6) Heatmap ----\np_filedb_heatmap <- ggplot(\n  filedb_long,\n  aes(x = Category, y = api_call, fill = z_mean_calls)\n) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"B\",\n    name   = \"Z-scored\\nmean calls\"\n  ) +\n  labs(\n    title    = \"File I/O and database activity by malware category\",\n    subtitle = \"Z-scored mean call counts per API; APIs with no variance removed, rows/cols clustered\",\n    x = \"Malware category\",\n    y = \"File / DB API\"\n  ) +\n  andmal_theme +\n  theme(\n    panel.grid = element_blank()\n  )\n\np_filedb_heatmap\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/plot-memory-1.png){width=960}\n:::\n\n```{.r .cell-code}\n# Heatmap All categories: reads vs writes ---- \n# Filter to categories with sufficient non-zero data points AND variance for density estimation\ndb_data <- get_combined_data() %>%\n  group_by(Category) %>%\n  summarise(\n    non_zero_count = sum(log_DB_reads > 0 | log_DB_writes > 0),\n    reads_var = var(log_DB_reads, na.rm = TRUE),\n    writes_var = var(log_DB_writes, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(\n    non_zero_count >= 50,  # Require at least 50 non-zero points\n    reads_var > 0.01,      # Require minimum variance in reads\n    writes_var > 0.01      # Require minimum variance in writes\n  ) %>%\n  left_join(get_combined_data(), by = \"Category\")\n\n# Create separate dataset for density estimation (non-zero points only)\n# This prevents bandwidth estimation failures when there are too many zeros\ndb_data_density <- db_data %>%\n  filter(log_DB_reads > 0 | log_DB_writes > 0)\n\np_db_read_write <- ggplot(\n  db_data,\n  aes(x = log_DB_reads, y = log_DB_writes)\n) +\n  # Use non-zero data for density estimation to avoid bandwidth issues\n  ggdensity::geom_hdr(\n    data = db_data_density,\n    aes(fill = after_stat(probs)),\n    probs = c(.99, .95, .80, .50),\n    n = 300,\n    alpha = 0.6  # Lower alpha for better visibility\n  ) +\n  facet_wrap(~ Category, scales = \"free\") +  # Free scales for better visibility of each category\n  scale_fill_viridis_d(\n    option = \"inferno\",\n    name = \"Density Level\",\n    labels = c(\"99%\", \"95%\", \"80%\", \"50%\"),\n    guide = guide_legend()\n  ) +\n  labs(\n    title    = \"Database read vs write activity by category\",\n    subtitle = \"log10(total DB reads + 1) vs log10(total DB writes + 1) per sample, facetted by category (density estimated from non-zero points only; categories with <50 non-zero points or low variance excluded)\",\n    x = \"log10(total DB read calls + 1)\",\n    y = \"log10(total DB write calls + 1)\"\n  ) +\n  andmal_theme\n\np_db_read_write\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/plot-memory-2.png){width=960}\n:::\n\n```{.r .cell-code}\n# Memory Activities vs WebViews by category ----\n# Filter to categories with sufficient data points where BOTH dimensions are non-zero\n# This is required for proper bandwidth estimation in density plots\nmemory_data_summary <- get_combined_data() %>%\n  group_by(Category) %>%\n  summarise(\n    both_nonzero_count = sum(Memory_Activities > 0 & Memory_WebViews > 0),\n    .groups = \"drop\"\n  ) %>%\n  filter(both_nonzero_count >= 50)  # Require at least 50 points with both > 0\n\n# Calculate variance and unique values on the both > 0 subset for each category\n# Need sufficient unique values for kernel density estimation to work\nmemory_data_variance <- get_combined_data() %>%\n  filter(Memory_Activities > 0 & Memory_WebViews > 0) %>%\n  group_by(Category) %>%\n  summarise(\n    activities_var = var(Memory_Activities, na.rm = TRUE),\n    webviews_var = var(Memory_WebViews, na.rm = TRUE),\n    activities_unique = length(unique(Memory_Activities)),\n    webviews_unique = length(unique(Memory_WebViews)),\n    .groups = \"drop\"\n  ) %>%\n  filter(\n    activities_var > 0.01,      # Require minimum variance in activities\n    webviews_var > 0.01,         # Require minimum variance in webviews\n    activities_unique >= 5,       # Require minimum unique values for density estimation\n    webviews_unique >= 5         # Require minimum unique values for density estimation\n  )\n\n# Get categories that pass both filters\nvalid_categories <- intersect(memory_data_summary$Category, memory_data_variance$Category)\n\n# Filter full data to valid categories\nmemory_data <- get_combined_data() %>%\n  filter(Category %in% valid_categories)\n\n# Create separate dataset for density estimation (both dimensions > 0 only)\n# This prevents bandwidth estimation failures when one dimension has many zeros\nmemory_data_density <- memory_data %>%\n  filter(Memory_Activities > 0 & Memory_WebViews > 0)\n\np_memory_activities_webviews <- ggplot(\n  memory_data,\n  aes(x = Memory_Activities, y = Memory_WebViews)\n) +\n  # Use non-zero data for density estimation to avoid bandwidth issues\n  ggdensity::geom_hdr(\n    data = memory_data_density,\n    aes(fill = after_stat(probs)),\n    probs = c(.99, .95, .80, .50),\n    n = 300,\n    alpha = 0.6  # Lower alpha for better visibility\n  ) +\n  facet_wrap(~ Category, scales = \"free\") +  # Free scales for better visibility of each category\n  scale_fill_viridis_d(\n    option = \"inferno\",\n    name = \"Density Level\",\n    labels = c(\"99%\", \"95%\", \"80%\", \"50%\"),\n    guide = guide_legend()\n  ) +\n  labs(\n    title    = \"Memory Activities vs WebViews by category\",\n    subtitle = \"Memory_Activities vs Memory_WebViews per sample, facetted by category (density estimated from points where both dimensions > 0; categories with <50 such points or low variance excluded)\",\n    x = \"Memory_Activities\",\n    y = \"Memory_WebViews\"\n  ) +\n  andmal_theme\n\np_memory_activities_webviews\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/plot-memory-3.png){width=960}\n:::\n\n```{.r .cell-code}\n## 2. Keep only those Dex columns that actually exist in your data ----\n# (Optional) See which ones were missing:\nsetdiff(dex_apis, names(andmal_before))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"API_DexClassLoader_dalvik.system.DexClassLoader_.init\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# You can inspect this in the console if you're curious.\n\n## 3. Summarise per Category: proportion of samples with any Dex loading ----\n# (Moved to index.qmd)\n\n\n\n#IPC/Binder plots\n```\n:::\n\n\n### IPC/Binder plots\n\nWe'll group APIs into 4 behaviors:\n\nBroadcasts - sendBroadcast / sendStickyBroadcast\n\nServices - startService / stopService\n\nReceivers - any *_registerReceiver / ActivityThread_handleReceiver\n\nActivities - any *_startActivity\n\nThen compute, for each Category, the proportion of samples that use each behavior at least once.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build per-sample flags for each IPC behavior group ----\nipc_group_summary <- get_combined_data() %>%\n  select(Category, has_broadcast, has_service, has_receiver, has_activity) %>%\n  pivot_longer(\n    cols      = c(has_broadcast, has_service, has_receiver, has_activity),\n    names_to  = \"ipc_group\",\n    values_to = \"present\"\n  ) %>%\n  mutate(\n    ipc_group = recode(\n      ipc_group,\n      has_broadcast = \"Broadcasts\",\n      has_service   = \"Services\",\n      has_receiver  = \"Receivers\",\n      has_activity  = \"Activities\"\n    )\n  ) %>%\n  group_by(Category, ipc_group) %>%\n  summarise(\n    prop_present = mean(present, na.rm = TRUE),\n    n_samples    = n(),\n    .groups      = \"drop\"\n  )\n\n# Bar chart: proportion by Category & IPC group ----\np_ipc_groups <- ggplot(\n  ipc_group_summary,\n  aes(x = Category, y = prop_present, fill = ipc_group)\n) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_viridis_d(\n    option = \"D\",\n    end    = 0.9,\n    name   = \"IPC/Binder behavior\"\n  ) +\n  labs(\n    title    = \"IPC, Binder & broadcast behavior by malware category\",\n    subtitle = \"Proportion of samples that use each IPC group at least once\",\n    x = \"Malware category\",\n    y = \"% of samples\"\n  ) +\n  andmal_theme +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\np_ipc_groups\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/ipc-behaviors-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Privacy\np_pii_index <- ggplot(\n  get_combined_data(),\n  aes(x = Category, y = log_PII_access, fill = Category)\n) +\n  geom_violin(trim = FALSE, alpha = 0.8) +\n  category_fill +\n  labs(\n    title    = \"PII access intensity by malware category\",\n    subtitle = \"log10(PII_access_count + 1), where PII = IDs + accounts + location + mic calls\",\n    x = \"Malware category\",\n    y = \"log10(PII_access_count + 1)\"\n  ) +\n  andmal_theme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\np_pii_index\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/ipc-behaviors-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Long + summary for PII type proportions\npii_long <- get_combined_data() %>%\n  select(Category, has_ids, has_accounts, has_location, has_mic) %>%\n  pivot_longer(\n    cols      = c(has_ids, has_accounts, has_location, has_mic),\n    names_to  = \"pii_type\",\n    values_to = \"present\"\n  ) %>%\n  mutate(\n    pii_type = recode(\n      pii_type,\n      has_ids      = \"Identifiers (device + WiFi)\",\n      has_accounts = \"Accounts & content\",\n      has_location = \"Location\",\n      has_mic      = \"Microphone\"\n    )\n  )\n\npii_summary <- pii_long %>%\n  group_by(Category, pii_type) %>%\n  summarise(\n    prop_present = mean(present, na.rm = TRUE),\n    n_samples    = n(),\n    .groups      = \"drop\"\n  )\n\n# Stacked bar per Category: what PII is accessed?\np_pii_type <- ggplot(\n  pii_summary,\n  aes(x = Category, y = prop_present, fill = pii_type)\n) +\n  geom_col(position = \"stack\") +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_viridis_d(\n    option = \"D\",\n    end    = 0.9,\n    name   = \"PII type\"\n  ) +\n  labs(\n    title    = \"Types of PII accessed by malware category\",\n    subtitle = \"Each bar shows the proportion of samples accessing different PII types (may overlap)\",\n    x = \"Malware category\",\n    y = \"% of samples\"\n  ) +\n  andmal_theme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\np_pii_type\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/ipc-behaviors-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Long format for location/mic + reboot_state\nloc_mic_long <- get_combined_data() %>%\n  mutate(\n    has_location = location_calls > 0,\n    has_mic      = mic_calls      > 0\n  ) %>%\n  select(Category, reboot_state, has_location, has_mic) %>%\n  pivot_longer(\n    cols      = c(has_location, has_mic),\n    names_to  = \"sensor_type\",\n    values_to = \"present\"\n  ) %>%\n  mutate(\n    sensor_type = recode(\n      sensor_type,\n      has_location = \"Location\",\n      has_mic      = \"Microphone\"\n    )\n  )\n\nloc_mic_summary <- loc_mic_long %>%\n  group_by(Category, reboot_state, sensor_type) %>%\n  summarise(\n    prop_present = mean(present, na.rm = TRUE),\n    n_samples    = n(),\n    .groups      = \"drop\"\n  )\n\n# Bar chart: before vs after reboot for location/mic\np_loc_mic_reboot <- ggplot(\n  loc_mic_summary,\n  aes(x = Category, y = prop_present, fill = reboot_state)\n) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ sensor_type) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_manual(\n    values = c(\"Before reboot\" = \"#440154FF\", \"After reboot\" = \"#21908CFF\"),\n    name   = \"Reboot state\"\n  ) +\n  labs(\n    title    = \"Location and microphone access: before vs after reboot\",\n    subtitle = \"Proportion of samples touching location/mic APIs, by category & reboot state\",\n    x = \"Malware category\",\n    y = \"% of samples\"\n  ) +\n  andmal_theme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\np_loc_mic_reboot\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/ipc-behaviors-4.png){width=672}\n:::\n:::\n\n\n## Dynamic Code Loading Analysis\n\nDynamic code loading through DexClassLoader APIs varies significantly across malware categories, with some categories showing higher adoption rates than others. This analysis examines the prevalence of dynamic code loading techniques used by different malware types.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Summarise per Category: proportion of samples with any Dex loading\ndex_summary <- get_combined_data() %>%\n  group_by(Category) %>%\n  summarise(\n    prop_dex_any = mean(dex_any, na.rm = TRUE),\n    n_samples    = n(),\n    .groups      = \"drop\"\n  )\n\n# Bar chart: % of apps using Dex loading, by Category\np_dex_bar <- ggplot(\n  dex_summary,\n  aes(x = Category, y = prop_dex_any, fill = Category)\n) +\n  geom_col() +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_manual(values = rep(\"red\", length(unique(dex_summary$Category)))) +\n  labs(\n    title = \"Dynamic Dex loading by malware category\",\n    subtitle = \"Percentage of samples that use any DexClassLoader / DexFile dynamic loading API\",\n    x = \"Malware category\",\n    y = \"% of samples with dynamic Dex loading\"\n  ) +\n  andmal_theme +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n  )\n\np_dex_bar\n```\n\n::: {.cell-output-display}\n![](edav_files/figure-html/dynamic-dex-chart-1.png){width=672}\n:::\n:::\n\n\n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}