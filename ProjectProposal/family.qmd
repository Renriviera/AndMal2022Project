---
title: "Family Prediction Models"
format: html
---

This document trains three category-specific random forest models to predict malware family within each category (Adware, Riskware, and Trojan).

## Load Libraries and Data

```{r}
#| label: load-libraries
#| cache: true

library(ranger)
library(dplyr)
library(caret)
library(parallel)
library(lime)
library(fastshap)
library(ggplot2)
library(stringr)

# Configuration
num_threads <- 8L
num_trees <- 500L
train_test_split <- 0.8
```

```{r}
#| label: load-processed-data
#| cache: true

# Load preprocessed data (from preprocessing.qmd)
andmal_after <- readRDS("data/processed/andmal_after.rds")

cat(sprintf("Loaded dataset: %d rows, %d columns\n", nrow(andmal_after), ncol(andmal_after)))
```

## Feature Selection

```{r}
#| label: identify-features
#| cache: true

# Metadata columns to exclude from features (keep only Category)
metadata_cols <- c("Family", "Category_file", "reboot_state", "path", "file", "Hash")

# Get all column names
all_cols <- names(andmal_after)

# Identify metadata columns that actually exist
metadata_cols_present <- intersect(metadata_cols, all_cols)

# Feature columns for family prediction (exclude metadata, keep Category)
feature_cols_family <- setdiff(all_cols, metadata_cols_present)

# Additional exclusion: any rank/color columns
feature_cols_family <- feature_cols_family[!str_detect(feature_cols_family, "rank|color|fam_color|rank_in_cat")]

cat(sprintf("Family prediction features: %d features\n", length(feature_cols_family)))
cat(sprintf("Excluded metadata columns: %s\n", paste(metadata_cols_present, collapse = ", ")))
```

## Train Category-Specific Models

```{r}
#| label: train-models
#| cache: false

# Categories to model
target_categories <- c("Adware", "Riskware", "Trojan")

# Storage for models and training data
category_models <- list()
category_train_data_list <- list()

# Calculate mtry for family models
mtry_family <- floor(sqrt(length(feature_cols_family)))

caret_available <- require("caret", quietly = TRUE)

cat(sprintf("Family prediction parameters:\n"))
cat(sprintf("  Number of trees: %d\n", num_trees))
cat(sprintf("  mtry: %d (sqrt of %d features)\n", mtry_family, length(feature_cols_family)))
cat(sprintf("  Number of threads: %d\n", num_threads))

# Train a model for each category
for (category in target_categories) {
  cat(sprintf("\n--- Training Model for %s Family Prediction ---\n", category))
  
  # Filter data for this category
  category_data <- andmal_after %>%
    filter(Category == category)
  
  if (nrow(category_data) == 0) {
    cat(sprintf("  WARNING: No samples found for category '%s'. Skipping.\n", category))
    next
  }
  
  # Check family distribution
  family_dist <- table(category_data$Family)
  cat(sprintf("  Samples in %s category: %d\n", category, nrow(category_data)))
  cat(sprintf("  Number of families: %d\n", length(unique(category_data$Family))))
  
  # Skip if too few families or samples
  if (length(unique(category_data$Family)) < 2) {
    cat(sprintf("  WARNING: Category '%s' has fewer than 2 families. Skipping.\n", category))
    next
  }
  
  if (nrow(category_data) < 50) {
    cat(sprintf("  WARNING: Category '%s' has fewer than 50 samples. Skipping.\n", category))
    next
  }
  
  # Create train/test split stratified by Family
  set.seed(42)
  if (caret_available) {
    category_train_index <- caret::createDataPartition(
      category_data$Family,
      p = train_test_split,
      list = FALSE,
      times = 1
    )
    category_train <- category_data[category_train_index, ]
    category_test <- category_data[-category_train_index, ]
  } else {
    # Base R stratified sampling by Family
    families <- unique(category_data$Family)
    train_indices <- c()
    for (fam in families) {
      fam_indices <- which(category_data$Family == fam)
      if (length(fam_indices) > 1) {
        n_train <- max(1, round(length(fam_indices) * train_test_split))
        train_fam_indices <- sample(fam_indices, n_train)
        train_indices <- c(train_indices, train_fam_indices)
      } else {
        # If only one sample, put it in training
        train_indices <- c(train_indices, fam_indices)
      }
    }
    category_train <- category_data[train_indices, ]
    category_test <- category_data[-train_indices, ]
  }
  
  cat(sprintf("  Training set: %d samples\n", nrow(category_train)))
  cat(sprintf("  Test set: %d samples\n", nrow(category_test)))
  
  # Prepare data for training (ensure data.frame, not tibble)
  train_family_x <- as.data.frame(category_train[, feature_cols_family, drop = FALSE])
  train_family_y <- category_train$Family
  test_family_x <- as.data.frame(category_test[, feature_cols_family, drop = FALSE])
  test_family_y <- category_test$Family
  
  # Ensure Family factor levels match
  train_family_y <- factor(train_family_y, levels = unique(c(train_family_y, test_family_y)))
  test_family_y <- factor(test_family_y, levels = levels(train_family_y))
  
  # Train model
  cat(sprintf("  Training random forest for %s family prediction...\n", category))
  start_time <- Sys.time()
  
  rf_family <- ranger(
    x = train_family_x,
    y = train_family_y,
    num.trees = num_trees,
    mtry = mtry_family,
    min.node.size = 1,
    num.threads = num_threads,
    classification = TRUE,
    probability = TRUE,
    importance = "impurity",
    verbose = FALSE
  )
  
  end_time <- Sys.time()
  training_time <- difftime(end_time, start_time, units = "mins")
  cat(sprintf("  Training completed in %.2f minutes\n", as.numeric(training_time)))
  
  # Store model and training data (needed for LIME/SHAP)
  category_models[[category]] <- rf_family
  
  # Save model
  if (!dir.exists("data/models")) {
    dir.create("data/models", recursive = TRUE)
  }
  model_name <- paste0("data/models/rf_family_", tolower(category), "_model.rds")
  saveRDS(rf_family, model_name)
  cat(sprintf("  Saved: %s\n", model_name))
  
  # Store training data for this category (needed for LIME/SHAP explanations)
  # Save as data.frame to avoid tibble issues
  category_train_data_list[[category]] <- list(
    train_x = train_family_x,
    train_y = train_family_y
  )
}

cat("\nAll family models trained successfully.\n")
```

## Load Selected Instances

```{r}
#| label: load-selected-instances
#| cache: true

# Set seed for reproducibility
set.seed(42)

# Load the selected instances from category.qmd
if (file.exists("data/processed/selected_instances.rds")) {
  selected_instances_df <- readRDS("data/processed/selected_instances.rds")
  cat("Loaded selected instances from category.qmd\n")
  cat(sprintf("Selected instances: %s\n", paste(selected_instances_df$Category, collapse = ", ")))
} else {
  stop("Selected instances file not found. Please run category.qmd first to generate selected_instances.rds")
}

# Extract feature matrices for explanations (same pattern as category.qmd)
selected_instances_x <- selected_instances_df[, feature_cols_family, drop = FALSE]

cat("\nInstance selection complete.\n")
```

## Model Interpretability

### Adware Family Model Explanations

```{r}
#| label: adware-lime-shap
#| cache: false
#| fig.width: 12
#| fig.height: 8

# Set seed for reproducibility
set.seed(42)

category <- "Adware"

if (category %in% names(category_models)) {
  cat(sprintf("\n=== %s Family Model Explanations ===\n", category))
  
  # Get the corresponding instance (same pattern as category.qmd)
  instance_idx <- which(selected_instances_df$Category == category)
  if (length(instance_idx) == 0) {
    cat(sprintf("No instance found for category %s\n", category))
  } else {
    # Get training data for this category
    train_family_x <- category_train_data_list[[category]]$train_x
    model <- category_models[[category]]
    
    #### LIME Explanation
    cat(sprintf("\n--- LIME Explanation for %s Instance ---\n", category))
    
    # Create LIME explainer
    explainer_family <- lime(
      train_family_x,
      model = model,
      bin_continuous = TRUE,
      n_bins = 5
    )
    
    # Extract instance (same pattern as category.qmd)
    instance_x <- as.data.frame(selected_instances_x[instance_idx, , drop = FALSE])
    
    lime_explanation <- lime::explain(
      instance_x,
      explainer = explainer_family,
      n_features = 10,
      n_permutations = 5000,
      n_labels = 1
    )
    
    cat("LIME Explanation:\n")
    # Ensure explanation has proper structure for plotting
    if (nrow(lime_explanation) > 0) {
      # If explanation doesn't have 'case' column, add it
      if (!"case" %in% colnames(lime_explanation)) {
        lime_explanation$case <- 1
      }
      print(plot_features(lime_explanation))
    } else {
      cat("Warning: LIME explanation is empty. Skipping plot.\n")
    }
    
    #### Per-Instance SHAP Values
    cat(sprintf("\n--- Per-Instance SHAP Values for %s Instance ---\n", category))
    
    # Create prediction function for fastshap
    pred_wrapper_family <- function(object, newdata) {
      pred <- predict(object, newdata)
      return(pred$predictions)
    }
    
    # Ensure newdata is a data.frame (same pattern as category.qmd)
    newdata_df <- as.data.frame(selected_instances_x[instance_idx, , drop = FALSE])
    
    shap_instance <- explain(
      model,
      X = train_family_x,
      newdata = newdata_df,
      pred_wrapper = pred_wrapper_family,
      nsim = 100
    )
    
    # Get predicted class probabilities
    pred_probs <- predict(model, newdata_df)$predictions
    pred_class <- colnames(pred_probs)[which.max(pred_probs)]
    
    # Handle SHAP values - fastshap returns a matrix/data.frame
    if (is.data.frame(shap_instance) || is.matrix(shap_instance)) {
      # Check if columns are classes or features
      if (pred_class %in% colnames(shap_instance)) {
        shap_df <- data.frame(
          feature = rownames(shap_instance),
          shap_value = shap_instance[[pred_class]]
        )
      } else if (ncol(shap_instance) == length(feature_cols_family)) {
        # Columns are features
        shap_df <- data.frame(
          feature = colnames(shap_instance),
          shap_value = as.numeric(shap_instance[1, ])
        )
      } else {
        # Try to extract first row or first column
        if (nrow(shap_instance) == 1) {
          shap_df <- data.frame(
            feature = colnames(shap_instance),
            shap_value = as.numeric(shap_instance[1, ])
          )
        } else {
          shap_df <- data.frame(
            feature = rownames(shap_instance),
            shap_value = as.numeric(shap_instance[, 1])
          )
        }
      }
      
      shap_df <- shap_df %>%
        arrange(desc(abs(shap_value))) %>%
        head(20)
      
      cat(sprintf("Top 20 SHAP values (predicted class: %s):\n", pred_class))
      print(shap_df)
      
      # Determine the order of magnitude (exponent) for scientific notation
      max_abs_value <- max(abs(shap_df$shap_value))
      if (max_abs_value > 0) {
        exponent <- floor(log10(max_abs_value))
        # Round to nearest multiple of 3 for cleaner display
        exponent <- round(exponent / 3) * 3
      } else {
        exponent <- 0
      }
      
      # Create custom label function that shows only significant digits
      # and scales by the exponent
      scale_factor <- 10^(-exponent)
      label_func <- function(x) {
        scaled <- x * scale_factor
        # Format with appropriate decimal places
        if (abs(exponent) >= 3) {
          sprintf("%.3f", scaled)
        } else {
          sprintf("%.4f", scaled)
        }
      }
      
      # Create visualization
      y_axis_label <- if (abs(exponent) >= 3) {
        sprintf("SHAP Value (×10^%d)", exponent)
      } else {
        "SHAP Value"
      }
      
      p_shap <- ggplot(shap_df, aes(x = reorder(feature, shap_value), y = shap_value)) +
        geom_col(aes(fill = shap_value > 0)) +
        scale_fill_manual(
          values = c("TRUE" = "#2E8B57", "FALSE" = "#DC143C"),
          labels = c("TRUE" = "Positive", "FALSE" = "Negative"),
          name = "SHAP Value"
        ) +
        scale_y_continuous(labels = label_func) +
        coord_flip() +
        labs(
          title = sprintf("SHAP Values - %s Instance (%s Family Model)", category, pred_class),
          subtitle = sprintf("Top 20 features by absolute SHAP value"),
          x = "Feature",
          y = y_axis_label
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 14, face = "bold"),
          plot.subtitle = element_text(size = 12),
          axis.text.y = element_text(size = 8)
        )
      
      print(p_shap)
    } else {
      cat(sprintf("SHAP values format not recognized for %s instance\n", category))
    }
  }
} else {
  cat(sprintf("Model for %s not found.\n", category))
}
```

### Riskware Family Model Explanations

```{r}
#| label: riskware-lime-shap
#| cache: false
#| fig.width: 12
#| fig.height: 8

# Set seed for reproducibility
set.seed(42)

category <- "Riskware"

if (category %in% names(category_models)) {
  cat(sprintf("\n=== %s Family Model Explanations ===\n", category))
  
  # Get the corresponding instance (same pattern as category.qmd)
  instance_idx <- which(selected_instances_df$Category == category)
  if (length(instance_idx) == 0) {
    cat(sprintf("No instance found for category %s\n", category))
  } else {
    # Get training data for this category
    train_family_x <- category_train_data_list[[category]]$train_x
    model <- category_models[[category]]
    
    #### LIME Explanation
    cat(sprintf("\n--- LIME Explanation for %s Instance ---\n", category))
    
    # Create LIME explainer
    explainer_family <- lime(
      train_family_x,
      model = model,
      bin_continuous = TRUE,
      n_bins = 5
    )
    
    # Extract instance (same pattern as category.qmd)
    instance_x <- as.data.frame(selected_instances_x[instance_idx, , drop = FALSE])
    
    lime_explanation <- lime::explain(
      instance_x,
      explainer = explainer_family,
      n_features = 10,
      n_permutations = 5000,
      n_labels = 1
    )
    
    cat("LIME Explanation:\n")
    # Ensure explanation has proper structure for plotting
    if (nrow(lime_explanation) > 0) {
      # If explanation doesn't have 'case' column, add it
      if (!"case" %in% colnames(lime_explanation)) {
        lime_explanation$case <- 1
      }
      print(plot_features(lime_explanation))
    } else {
      cat("Warning: LIME explanation is empty. Skipping plot.\n")
    }
    
    #### Per-Instance SHAP Values
    cat(sprintf("\n--- Per-Instance SHAP Values for %s Instance ---\n", category))
    
    # Create prediction function for fastshap
    pred_wrapper_family <- function(object, newdata) {
      pred <- predict(object, newdata)
      return(pred$predictions)
    }
    
    # Ensure newdata is a data.frame (same pattern as category.qmd)
    newdata_df <- as.data.frame(selected_instances_x[instance_idx, , drop = FALSE])
    
    shap_instance <- explain(
      model,
      X = train_family_x,
      newdata = newdata_df,
      pred_wrapper = pred_wrapper_family,
      nsim = 100
    )
    
    # Get predicted class probabilities
    pred_probs <- predict(model, newdata_df)$predictions
    pred_class <- colnames(pred_probs)[which.max(pred_probs)]
    
    # Handle SHAP values - fastshap returns a matrix/data.frame
    if (is.data.frame(shap_instance) || is.matrix(shap_instance)) {
      # Check if columns are classes or features
      if (pred_class %in% colnames(shap_instance)) {
        shap_df <- data.frame(
          feature = rownames(shap_instance),
          shap_value = shap_instance[[pred_class]]
        )
      } else if (ncol(shap_instance) == length(feature_cols_family)) {
        # Columns are features
        shap_df <- data.frame(
          feature = colnames(shap_instance),
          shap_value = as.numeric(shap_instance[1, ])
        )
      } else {
        # Try to extract first row or first column
        if (nrow(shap_instance) == 1) {
          shap_df <- data.frame(
            feature = colnames(shap_instance),
            shap_value = as.numeric(shap_instance[1, ])
          )
        } else {
          shap_df <- data.frame(
            feature = rownames(shap_instance),
            shap_value = as.numeric(shap_instance[, 1])
          )
        }
      }
      
      shap_df <- shap_df %>%
        arrange(desc(abs(shap_value))) %>%
        head(20)
      
      cat(sprintf("Top 20 SHAP values (predicted class: %s):\n", pred_class))
      print(shap_df)
      
      # Determine the order of magnitude (exponent) for scientific notation
      max_abs_value <- max(abs(shap_df$shap_value))
      if (max_abs_value > 0) {
        exponent <- floor(log10(max_abs_value))
        # Round to nearest multiple of 3 for cleaner display
        exponent <- round(exponent / 3) * 3
      } else {
        exponent <- 0
      }
      
      # Create custom label function that shows only significant digits
      # and scales by the exponent
      scale_factor <- 10^(-exponent)
      label_func <- function(x) {
        scaled <- x * scale_factor
        # Format with appropriate decimal places
        if (abs(exponent) >= 3) {
          sprintf("%.3f", scaled)
        } else {
          sprintf("%.4f", scaled)
        }
      }
      
      # Create visualization
      y_axis_label <- if (abs(exponent) >= 3) {
        sprintf("SHAP Value (×10^%d)", exponent)
      } else {
        "SHAP Value"
      }
      
      p_shap <- ggplot(shap_df, aes(x = reorder(feature, shap_value), y = shap_value)) +
        geom_col(aes(fill = shap_value > 0)) +
        scale_fill_manual(
          values = c("TRUE" = "#2E8B57", "FALSE" = "#DC143C"),
          labels = c("TRUE" = "Positive", "FALSE" = "Negative"),
          name = "SHAP Value"
        ) +
        scale_y_continuous(labels = label_func) +
        coord_flip() +
        labs(
          title = sprintf("SHAP Values - %s Instance (%s Family Model)", category, pred_class),
          subtitle = sprintf("Top 20 features by absolute SHAP value"),
          x = "Feature",
          y = y_axis_label
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 14, face = "bold"),
          plot.subtitle = element_text(size = 12),
          axis.text.y = element_text(size = 8)
        )
      
      print(p_shap)
    } else {
      cat(sprintf("SHAP values format not recognized for %s instance\n", category))
    }
  }
} else {
  cat(sprintf("Model for %s not found.\n", category))
}
```

### Trojan Family Model Explanations

```{r}
#| label: trojan-lime-shap
#| cache: false
#| fig.width: 12
#| fig.height: 8

# Set seed for reproducibility
set.seed(42)

category <- "Trojan"

if (category %in% names(category_models)) {
  cat(sprintf("\n=== %s Family Model Explanations ===\n", category))
  
  # Get the corresponding instance (same pattern as category.qmd)
  instance_idx <- which(selected_instances_df$Category == category)
  if (length(instance_idx) == 0) {
    cat(sprintf("No instance found for category %s\n", category))
  } else {
    # Get training data for this category
    train_family_x <- category_train_data_list[[category]]$train_x
    model <- category_models[[category]]
    
    #### LIME Explanation
    cat(sprintf("\n--- LIME Explanation for %s Instance ---\n", category))
    
    # Create LIME explainer
    explainer_family <- lime(
      train_family_x,
      model = model,
      bin_continuous = TRUE,
      n_bins = 5
    )
    
    # Extract instance (same pattern as category.qmd)
    instance_x <- as.data.frame(selected_instances_x[instance_idx, , drop = FALSE])
    
    lime_explanation <- lime::explain(
      instance_x,
      explainer = explainer_family,
      n_features = 10,
      n_permutations = 5000,
      n_labels = 1
    )
    
    cat("LIME Explanation:\n")
    # Ensure explanation has proper structure for plotting
    if (nrow(lime_explanation) > 0) {
      # If explanation doesn't have 'case' column, add it
      if (!"case" %in% colnames(lime_explanation)) {
        lime_explanation$case <- 1
      }
      print(plot_features(lime_explanation))
    } else {
      cat("Warning: LIME explanation is empty. Skipping plot.\n")
    }
    
    #### Per-Instance SHAP Values
    cat(sprintf("\n--- Per-Instance SHAP Values for %s Instance ---\n", category))
    
    # Create prediction function for fastshap
    pred_wrapper_family <- function(object, newdata) {
      pred <- predict(object, newdata)
      return(pred$predictions)
    }
    
    # Ensure newdata is a data.frame (same pattern as category.qmd)
    newdata_df <- as.data.frame(selected_instances_x[instance_idx, , drop = FALSE])
    
    shap_instance <- explain(
      model,
      X = train_family_x,
      newdata = newdata_df,
      pred_wrapper = pred_wrapper_family,
      nsim = 100
    )
    
    # Get predicted class probabilities
    pred_probs <- predict(model, newdata_df)$predictions
    pred_class <- colnames(pred_probs)[which.max(pred_probs)]
    
    # Handle SHAP values - fastshap returns a matrix/data.frame
    if (is.data.frame(shap_instance) || is.matrix(shap_instance)) {
      # Check if columns are classes or features
      if (pred_class %in% colnames(shap_instance)) {
        shap_df <- data.frame(
          feature = rownames(shap_instance),
          shap_value = shap_instance[[pred_class]]
        )
      } else if (ncol(shap_instance) == length(feature_cols_family)) {
        # Columns are features
        shap_df <- data.frame(
          feature = colnames(shap_instance),
          shap_value = as.numeric(shap_instance[1, ])
        )
      } else {
        # Try to extract first row or first column
        if (nrow(shap_instance) == 1) {
          shap_df <- data.frame(
            feature = colnames(shap_instance),
            shap_value = as.numeric(shap_instance[1, ])
          )
        } else {
          shap_df <- data.frame(
            feature = rownames(shap_instance),
            shap_value = as.numeric(shap_instance[, 1])
          )
        }
      }
      
      shap_df <- shap_df %>%
        arrange(desc(abs(shap_value))) %>%
        head(20)
      
      cat(sprintf("Top 20 SHAP values (predicted class: %s):\n", pred_class))
      print(shap_df)
      
      # Determine the order of magnitude (exponent) for scientific notation
      max_abs_value <- max(abs(shap_df$shap_value))
      if (max_abs_value > 0) {
        exponent <- floor(log10(max_abs_value))
        # Round to nearest multiple of 3 for cleaner display
        exponent <- round(exponent / 3) * 3
      } else {
        exponent <- 0
      }
      
      # Create custom label function that shows only significant digits
      # and scales by the exponent
      scale_factor <- 10^(-exponent)
      label_func <- function(x) {
        scaled <- x * scale_factor
        # Format with appropriate decimal places
        if (abs(exponent) >= 3) {
          sprintf("%.3f", scaled)
        } else {
          sprintf("%.4f", scaled)
        }
      }
      
      # Create visualization
      y_axis_label <- if (abs(exponent) >= 3) {
        sprintf("SHAP Value (×10^%d)", exponent)
      } else {
        "SHAP Value"
      }
      
      p_shap <- ggplot(shap_df, aes(x = reorder(feature, shap_value), y = shap_value)) +
        geom_col(aes(fill = shap_value > 0)) +
        scale_fill_manual(
          values = c("TRUE" = "#2E8B57", "FALSE" = "#DC143C"),
          labels = c("TRUE" = "Positive", "FALSE" = "Negative"),
          name = "SHAP Value"
        ) +
        scale_y_continuous(labels = label_func) +
        coord_flip() +
        labs(
          title = sprintf("SHAP Values - %s Instance (%s Family Model)", category, pred_class),
          subtitle = sprintf("Top 20 features by absolute SHAP value"),
          x = "Feature",
          y = y_axis_label
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 14, face = "bold"),
          plot.subtitle = element_text(size = 12),
          axis.text.y = element_text(size = 8)
        )
      
      print(p_shap)
    } else {
      cat(sprintf("SHAP values format not recognized for %s instance\n", category))
    }
  }
} else {
  cat(sprintf("Model for %s not found.\n", category))
}
```
